{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://github.com/SATHVIKRAJU/Stock-Market-Prediction-using-Natural-Language-Processing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# eval\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(curr_model, range1, range2, predictions, test):\n",
    "    print(\"using model: \" + str(type(curr_model)))\n",
    "    print(\"using ngram range: (\" + str(range1) + \", \" + str(range2) + \")\")\n",
    "    print(classification_report(test[\"Label\"], predictions))\n",
    "    print(accuracy_score(test[\"Label\"], predictions))\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes' instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl's successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver, nurse turned solicitor</td>\n",
       "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "\n",
       "        Top2                             Top3  \\\n",
       "0  Scorecard  Hughes' instant hit buoys Blues   \n",
       "\n",
       "                                       Top4  \\\n",
       "0  Jack gets his skates on at ice-cold Alex   \n",
       "\n",
       "                                     Top5  \\\n",
       "0  Chaos as Maracana builds up for United   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "\n",
       "                               Top7                               Top8  \\\n",
       "0  Hungry Spurs sense rich pickings  Gunners so wide of an easy target   \n",
       "\n",
       "          ...                                             Top16  \\\n",
       "0         ...          Flintoff injury piles on woe for England   \n",
       "\n",
       "                                               Top17  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "\n",
       "                                 Top18                                 Top19  \\\n",
       "0  Kohl's successor drawn into scandal  The difference between men and women   \n",
       "\n",
       "                                 Top20  \\\n",
       "0  Sara Denver, nurse turned solicitor   \n",
       "\n",
       "                                            Top21  \\\n",
       "0  Diana's landmine crusade put Tories in a panic   \n",
       "\n",
       "                                               Top22             Top23  \\\n",
       "0  Yeltsin's resignation caught opposition flat-f...  Russian roulette   \n",
       "\n",
       "      Top24               Top25  \n",
       "0  Sold out  Recovering a title  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv('Data1.csv', encoding = \"ISO-8859-1\")\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "\n",
    "#train, test = train_test_split(data, test_size=0.1)\n",
    "\n",
    "\n",
    "train = data[data['Date'] < '20150101']\n",
    "test = data[data['Date'] > '20141231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a  hindrance to operations   extracts from the...</td>\n",
       "      <td>scorecard</td>\n",
       "      <td>hughes  instant hit buoys blues</td>\n",
       "      <td>jack gets his skates on at ice cold alex</td>\n",
       "      <td>chaos as maracana builds up for united</td>\n",
       "      <td>depleted leicester prevail as elliott spoils e...</td>\n",
       "      <td>hungry spurs sense rich pickings</td>\n",
       "      <td>gunners so wide of an easy target</td>\n",
       "      <td>derby raise a glass to strupar s debut double</td>\n",
       "      <td>southgate strikes  leeds pay the penalty</td>\n",
       "      <td>...</td>\n",
       "      <td>flintoff injury piles on woe for england</td>\n",
       "      <td>hunters threaten jospin with new battle of the...</td>\n",
       "      <td>kohl s successor drawn into scandal</td>\n",
       "      <td>the difference between men and women</td>\n",
       "      <td>sara denver  nurse turned solicitor</td>\n",
       "      <td>diana s landmine crusade put tories in a panic</td>\n",
       "      <td>yeltsin s resignation caught opposition flat f...</td>\n",
       "      <td>russian roulette</td>\n",
       "      <td>sold out</td>\n",
       "      <td>recovering a title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1  \\\n",
       "0  a  hindrance to operations   extracts from the...  scorecard   \n",
       "\n",
       "                                 2                                         3  \\\n",
       "0  hughes  instant hit buoys blues  jack gets his skates on at ice cold alex   \n",
       "\n",
       "                                        4  \\\n",
       "0  chaos as maracana builds up for united   \n",
       "\n",
       "                                                   5  \\\n",
       "0  depleted leicester prevail as elliott spoils e...   \n",
       "\n",
       "                                  6                                  7  \\\n",
       "0  hungry spurs sense rich pickings  gunners so wide of an easy target   \n",
       "\n",
       "                                               8  \\\n",
       "0  derby raise a glass to strupar s debut double   \n",
       "\n",
       "                                          9         ...          \\\n",
       "0  southgate strikes  leeds pay the penalty         ...           \n",
       "\n",
       "                                         15  \\\n",
       "0  flintoff injury piles on woe for england   \n",
       "\n",
       "                                                  16  \\\n",
       "0  hunters threaten jospin with new battle of the...   \n",
       "\n",
       "                                    17                                    18  \\\n",
       "0  kohl s successor drawn into scandal  the difference between men and women   \n",
       "\n",
       "                                    19  \\\n",
       "0  sara denver  nurse turned solicitor   \n",
       "\n",
       "                                               20  \\\n",
       "0  diana s landmine crusade put tories in a panic   \n",
       "\n",
       "                                                  21                22  \\\n",
       "0  yeltsin s resignation caught opposition flat f...  russian roulette   \n",
       "\n",
       "         23                  24  \n",
       "0  sold out  recovering a title  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuation marks\n",
    "slicedData= train.iloc[:,2:27]\n",
    "slicedData.replace(to_replace=\"[^a-zA-Z]\", value=\" \", regex=True, inplace=True)\n",
    "\n",
    "# Renaming column names for ease of access\n",
    "list1= [i for i in range(25)]\n",
    "new_Index=[str(i) for i in list1]\n",
    "slicedData.columns= new_Index\n",
    "slicedData.head(5)\n",
    "\n",
    "# Convertng headlines to lower case\n",
    "for index in new_Index:\n",
    "    slicedData[index]=slicedData[index].str.lower()\n",
    "slicedData.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = []\n",
    "for row in range(0,len(slicedData.index)):\n",
    "    headlines.append(' '.join(str(x) for x in slicedData.iloc[row,0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a  hindrance to operations   extracts from the leaked reports scorecard hughes  instant hit buoys blues jack gets his skates on at ice cold alex chaos as maracana builds up for united depleted leicester prevail as elliott spoils everton s party hungry spurs sense rich pickings gunners so wide of an easy target derby raise a glass to strupar s debut double southgate strikes  leeds pay the penalty hammers hand robson a youthful lesson saints party like it s      wear wolves have turned into lambs stump mike catches testy gough s taunt langer escapes to hit     flintoff injury piles on woe for england hunters threaten jospin with new battle of the somme kohl s successor drawn into scandal the difference between men and women sara denver  nurse turned solicitor diana s landmine crusade put tories in a panic yeltsin s resignation caught opposition flat footed russian roulette sold out recovering a title'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), RandomForestClassifier(), svm.SVC(), svm.LinearSVC(), KNeighborsClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "using ngram range: (1, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       186\n",
      "           1       0.86      0.86      0.86       192\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       378\n",
      "   macro avg       0.86      0.86      0.86       378\n",
      "weighted avg       0.86      0.86      0.86       378\n",
      "\n",
      "0.8571428571428571\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "using ngram range: (1, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83       186\n",
      "           1       0.83      0.87      0.85       192\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       378\n",
      "   macro avg       0.84      0.84      0.84       378\n",
      "weighted avg       0.84      0.84      0.84       378\n",
      "\n",
      "0.8412698412698413\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: <class 'sklearn.svm.classes.SVC'>\n",
      "using ngram range: (1, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       186\n",
      "           1       0.51      1.00      0.67       192\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       378\n",
      "   macro avg       0.25      0.50      0.34       378\n",
      "weighted avg       0.26      0.51      0.34       378\n",
      "\n",
      "0.5079365079365079\n",
      "------------\n",
      "using model: <class 'sklearn.svm.classes.LinearSVC'>\n",
      "using ngram range: (1, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       186\n",
      "           1       0.86      0.83      0.85       192\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       378\n",
      "   macro avg       0.85      0.85      0.85       378\n",
      "weighted avg       0.85      0.85      0.85       378\n",
      "\n",
      "0.8465608465608465\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "using ngram range: (1, 1)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18       186\n",
      "           1       0.53      1.00      0.70       192\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       378\n",
      "   macro avg       0.77      0.55      0.44       378\n",
      "weighted avg       0.76      0.56      0.44       378\n",
      "\n",
      "0.5555555555555556\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "using ngram range: (1, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       186\n",
      "           1       0.81      0.84      0.83       192\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       378\n",
      "   macro avg       0.82      0.82      0.82       378\n",
      "weighted avg       0.82      0.82      0.82       378\n",
      "\n",
      "0.8227513227513228\n",
      "------------\n",
      "using model: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "using ngram range: (1, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       186\n",
      "           1       0.86      0.85      0.85       192\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       378\n",
      "   macro avg       0.85      0.85      0.85       378\n",
      "weighted avg       0.85      0.85      0.85       378\n",
      "\n",
      "0.8518518518518519\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: <class 'sklearn.svm.classes.SVC'>\n",
      "using ngram range: (1, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       186\n",
      "           1       0.51      1.00      0.67       192\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       378\n",
      "   macro avg       0.25      0.50      0.34       378\n",
      "weighted avg       0.26      0.51      0.34       378\n",
      "\n",
      "0.5079365079365079\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model: <class 'sklearn.svm.classes.LinearSVC'>\n",
      "using ngram range: (1, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.82       186\n",
      "           1       0.82      0.83      0.82       192\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       378\n",
      "   macro avg       0.82      0.82      0.82       378\n",
      "weighted avg       0.82      0.82      0.82       378\n",
      "\n",
      "0.8201058201058201\n",
      "------------\n",
      "using model: <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "using ngram range: (1, 2)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.57       186\n",
      "           1       0.59      0.61      0.60       192\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       378\n",
      "   macro avg       0.58      0.58      0.58       378\n",
      "weighted avg       0.58      0.58      0.58       378\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5846560846560847\n",
      "------------\n",
      "using model: <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "using ngram range: (1, 3)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85       186\n",
      "           1       0.83      0.89      0.86       192\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       378\n",
      "   macro avg       0.86      0.85      0.85       378\n",
      "weighted avg       0.86      0.85      0.85       378\n",
      "\n",
      "0.8544973544973545\n",
      "------------\n",
      "using model: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "using ngram range: (1, 3)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       186\n",
      "           1       0.84      0.82      0.83       192\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       378\n",
      "   macro avg       0.83      0.83      0.83       378\n",
      "weighted avg       0.83      0.83      0.83       378\n",
      "\n",
      "0.8306878306878307\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for range1 in range(1, 4): #1 to 6\n",
    "    for range2 in range(1, 4):\n",
    "        if(range2 >= range1):\n",
    "            basictrain = basicvectorizer.fit_transform(headlines)\n",
    "            basictest = basicvectorizer.transform(testheadlines)\n",
    "            # iterate through models\n",
    "            for curr_model in models:\n",
    "                curr_model = curr_model.fit(basictrain, train[\"Label\"])\n",
    "                basicvectorizer = CountVectorizer(ngram_range=(range1,range2))\n",
    "                \n",
    "                \n",
    "                predictions = curr_model.predict(basictest)\n",
    "                #pd.crosstab(test[\"Label\"], predictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])\n",
    "                print_results(curr_model, range1, range2, predictions, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
